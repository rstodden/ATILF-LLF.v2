import json
import logging
import os


class XPParams:
    useModuloReduction = True
    usePMICalc = False
    sumAllComponents = None
    vectorOfSumAllVectors = None
    numberModuloReduction = 499
    twoD_feats = False
    new_y_number = None #73
    dropout = 0.025 #0.025
    useBatchGenerator = False
    use_extern_labels = False

    useMultiChannel = True

    use_feature_selection_mi = False
    use_feature_selection_chi = False
    use_feature_selection_percentile = False
    use_feature_selection_kbest = False
    numPerc = 1

    useCNNandSVM = False
    useCNNOnly = True
    numberOfClasses = 27 # possible to change to max(labels)+1 in oracles. This produces maybe different length of onehotvectors in different languages
    CNNlayerName = "hidden_layer"
    batchSize = 32
    num_epochs = 10
    dropout = 0.025
    kernelsize = [2,4,6]
    dim_hidden = 500
    filters = 32
    batchSize = 32
    dim_embedd = 32
    compile_metric = "fbeta_score"
    pooling = "maxpooling"

    feature_dir = False # when false choose one language, when true choose all languages in featuregroups
    buildModel = True
    buildSVM = False
    predictOnly = False
    nrRun = ''
    corpora_version = 1.0

    context_window = 5

    useAllFilters = False

    print_debug = False

    realExper = True
    baseline = False
    #useUniversalPOSTag = True

    includeEmbedding = True

    useCrossValidation = False

    useAutoGeneratedPOS = False
    useAutoGeneratedDEP = False

    useDynamicOracle = False
    usePerceptron = False

    experimental = True
    perceptronIterations = 5
    explorationIteration = perceptronIterations  # int(perceptronIterations  * .1)

    correctlyLearnedSentPercentage = 0.8
    randomTransitionPercentage = 0.1

    randomSelectionPercentage = 0.7

    onlineTrainingFold = 10
    currentIteration = 0

    @staticmethod
    def printState():
        logging.warn('Real Expermintation ' if XPParams.realExper else 'Expermintation Without Test dataset')
        logging.warn('Cross Validation: ' if XPParams.useCrossValidation else 'Train Data Set Evaluation')
        logging.warn(
            'Automatic Data' if XPParams.useAutoGeneratedDEP and XPParams.useAutoGeneratedPOS else 'Golden Data')

        if XPParams.baseline:
            logging.warn('Baseline System')
        elif XPParams.includeEmbedding:
            logging.warn('Embedding system')
        else:
            logging.warn('Basic transition system')

        if XPParams.useDynamicOracle:
            logging.warn('Dynamic Oracle : iterations: ' + str(XPParams.perceptronIterations))
        elif XPParams.useHybridOracle:
            logging.warn('Hybrid Oracle')
        else:
            logging.warn('Static Oracle')
        if not XPParams.useHybridOracle and not XPParams.useDynamicOracle:
            logging.warn('Manula perceptron' if XPParams.usePerceptron else 'Scikit classifier')


class PrintParams:
    createDictionary = True
    printReport = True
    printSentsWithEmbeddedMWEs = True
    printFeaturesOfSent = False


class Paths:
    xpName = ''
    languageName = ''
    projectPath = os.path.dirname(__file__)[:-len(os.path.basename(os.path.dirname(__file__)))]
    train_file_tsv = 'train.parsemetsv'
    train_file_conllu = 'train.conllu'
    test_file_tsv = 'test.parsemetsv'
    test_file_conllu = 'test.conllu'
    train_file = 'train.cupt' # "train.dev.cupt"
    test_file = 'dev.cupt' # 'test.blind.cupt'
    configFile = 'DE.json'
    extern_labels = ""
    descriptionPath = None
    configsFolder = os.path.join(projectPath, 'FeatureGroups')
    corporaPath = os.path.join(projectPath, "sharedtask/")
    iterationPath = os.path.join(projectPath, "Results/")
    langResultFolder = os.path.join(projectPath, "Results/")
    rootResultFolder = os.path.join(projectPath, "Results/")
    onlineTrainingReport = os.path.join(projectPath, "Results/")


class FeatParams:
    usePreciseDictionary = False

    # Featue extraction parameters
    useFirstBufferElement = True
    useSecondBufferElement = True
    useToken = True
    useLemma = True
    useTokenLength = False
    usePOS = True
    useUPOS = True
    useBiGram = True
    useTriGram = True
    use4Gram = True
    #useDistance = True
    useSyntax = True
    useLeftDeps = False
    useIsHead = False
    useMorphoInfo =True
    useSpaceAfterInfo = False

    usePPMI = False

    generateS0B2Bigram = True
    useDictionary = True

    historyLength1 = True
    historyLength2 = True
    historyLength3 = True
    useS0B0Distance = True
    useS0S1Distance = True
    useStackLength = True
    useBufferLength = False
    useSentenceLength = False

    enhanceMerge = False
    enableSingleMWE = False
    useLexic = True
    smartMWTDetection = True
    generateS1B1 = False

    NumOFSent = 'Sentences: '
    NumOFMWEs = '\nMWEs: '
    NumOFEmbedded = '\nEmbedded MWEs: '
    NumOFInterleaving = '\nInterleaving MWEs: '
    NumContinousMWEs = '\nContinous MWEs: '
    NumSingleWordMWEs = '\nSingle Word MWEs: '

    def __init__(self, filePath, corpus=None):

        with open(filePath, 'r') as configFile:
            config = json.load(configFile)

        if len(filePath.split('/')) > 0:
            Paths.xpName = filePath.split('/')[-1].split('.')[0]
            # Paths.configsFolder = filePath

        if "generateS1B1" in config.keys():
            FeatParams.generateS1B1 = config["generateS1B1"]

        if "enhanceMerge" in config.keys():
            FeatParams.enhanceMerge = config["enhanceMerge"]

        if "usePreciseDictionary" in config.keys():
            FeatParams.usePreciseDictionary = config["usePreciseDictionary"]

        if "useLexic" in config.keys():
            FeatParams.useLexic = config["useLexic"]

        if "enableSingleMWE" in config.keys():
            FeatParams.enableSingleMWE = config["enableSingleMWE"]
        if "useSpaceAfterInfo" in config.keys():
            FeatParams.useSpaceAfterInfo = config["useSpaceAfterInfo"]

        FeatParams.useFirstBufferElement = config["useFirstBufferElement"]
        FeatParams.useSecondBufferElement = config["useSecondBufferElement"]

        FeatParams.usePOS = config["UseLinguistInfo"]["usePOS"]
        FeatParams.useUPOS = config["UseLinguistInfo"]["useUPOS"]
        FeatParams.useLemma = config["UseLinguistInfo"]["useLemma"]
        FeatParams.useBiGram = config["UseLinguistInfo"]["useBiGram"]
        FeatParams.useTriGram = config["UseLinguistInfo"]["useTriGram"]
        FeatParams.use4Gram = config["UseLinguistInfo"]["use4Gram"]
        FeatParams.useMorphoInfo = config["UseLinguistInfo"]["useMorphoInfo"]
        FeatParams.useTokenLength = config["UseLinguistInfo"]["useTokenLength"]
        FeatParams.useSyntax = config["UseLinguistInfo"]["useSyntax"]
        FeatParams.useLeftDeps = config["UseLinguistInfo"]["useLeftDeps"]
        FeatParams.useIsHead = config["UseLinguistInfo"]["useIsHead"]

        FeatParams.useS0B0Distance = config["S0B0Distance"]
        FeatParams.useS0S1Distance = config["S0S1Distance"]
        FeatParams.useStackLength = config["useStackLength"]
        if "useBufferLength" in config.keys():
            FeatParams.useBufferLength = config["useBufferLength"]

        FeatParams.generateS0B2Bigram = config["generateS0B2Bigram"]

        FeatParams.useDictionary = config["useDictionary"]

        # seems to have no effect
        FeatParams.historyLength1 = config["useTransitionHistory"]["transitionHistoryLength1"]
        FeatParams.historyLength2 = config["useTransitionHistory"]["transitionHistoryLength2"]
        FeatParams.historyLength3 = config["useTransitionHistory"]["transitionHistoryLength3"]


    @staticmethod
    def toString():
        result = ''
        with open(os.path.join(Paths.configsFolder, Paths.languageName + '.json'), 'r') as configFile:
            config = json.load(configFile)
            for key in config.keys():
                if isinstance(config[key], bool):
                    result += str(key)
                    if config[key]:
                        result += ' = True\n\n'
                    else:
                        result += ' = False\n\n'

                elif isinstance(config[key], dict):
                    for subkey in config[key].keys():
                        if isinstance(config[key][subkey], bool):
                            result += str(subkey)
                            if config[key][subkey]:
                                result += ' = True\n\n'
                            else:
                                result += ' = False\n\n'
        return result


class Counters:
    shiftNum, completeNum, mWTCompleteNum, mergeNum = 0, 0, 0, 0
    reduceNum, whiteMergeNum, blackMergeNum = 0, 0, 0
    mergeAsIDNum, mergeAsLVCCauseNum, mergeAsLVCFullNum = 0, 0, 0
    mergeAsVPCSemiNum, mergeAsVPCFullNum = 0, 0
    mergeAsIReflVNum, mergeAsOTHNum, mergeAsMWTNum = 0, 0, 0
    mergeAsMVCNum, mergeAsIAVNum = 0, 0
    mergeAsLSICVNum = 0

    @staticmethod
    def initCounters():
        Counters.shiftNum, Counters.completeNum, Counters.mWTCompleteNum, Counters.mergeNum = 0, 0, 0, 0
        Counters.reduceNum, Counters.whiteMergeNum, Counters.blackMergeNum = 0, 0, 0
        Counters.mergeAsIDNum, Counters.mergeAsLVCCauseNum, Counters.mergeLVCFullNum = 0, 0, 0
        Counters.mergeAsVPCCauseNum, Counters.mergeAsVPCFullNum = 0, 0
        Counters.mergeAsIReflVNum, Counters.mergeAsOTHNum, Counters.mergeAsMWTNum = 0, 0, 0
        Counters.mergeAsIAVNum, Counters.mergeAsMVCNum, Counters.mergeAsLSICVNum = 0, 0, 0
